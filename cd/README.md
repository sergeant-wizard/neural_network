## Restricted Boltzmann Machine with Contrast Divergence

### 背景

[前回](https://github.com/sergeant-wizard/neural_network/tree/master/rbm)
のRBMにContrastive Divergenceを導入

### 結果

入力データを列方向に並べた行列 `input` を幾つか用意し、
それぞれの入力に対してネットワークが示す確率が正しいかを検証する。

input | Test No. | iterations | CD\_N
----- | -------- | ---------- | -----
0 0 0 | 0 | 4096 | 10
1 0 0 | 1 | 4096 | 10
1 0 0, 0 1 0 | 2 | 16384 | 10
1 0 0, 0 1 0, 0 0 1 | 3 | 65536 | 32

#### Test No. 0

単一の入力に対してのみ高い確率を示すことを確認。

input | actual | expected
----- | ------ | --------
000   |  0.932 | 1
100   |  0.021 | 0
010   |  0.018 | 0
110   |  0.002 | 0
001   |  0.020 | 0
101   |  0.003 | 0
011   |  0.002 | 0
111   |  0.002 | 0

#### Test No. 1

単一の入力に対してのみ高い確率を示すことを確認。

input | actual | expected
----- | ------ | --------
000   | 0.007  | 0
100   | 0.961  | 1
010   | 0.001  | 0
110   | 0.014  | 0
001   | 0.001  | 0
101   | 0.016  | 0
011   | 0.000  | 0
111   | 0.001  | 0

#### Test No. 2
期待通りの確率を示す。
ただし、反復回数を大きく取らないと以下の結果とならなかった。

input | actual | expected
----- | ------ | --------
000   | 0.046  | 0
100   | 0.449  | 0.5
010   | 0.440  | 0.5
110   | 0.052  | 0
001   | 0.001  | 0
101   | 0.006  | 0
011   | 0.005  | 0
111   | 0.001  | 0

#### Test No. 3
期待通りの確率を示す。
ただし、反復回数とCD\_Nを大きく取らないと以下の結果とならなかった。

input | actual | expected
----- | ------ | --------
000   |  0.008 | 0
100   |  0.337 | 0.333
010   |  0.307 | 0.333
110   |  0.006 | 0
001   |  0.329 | 0.333
101   |  0.006 | 0
011   |  0.006 | 0
111   |  0.001 | 0

## まとめ

CDを利用して期待通りの確率を得ることができた。

Test No. 2の場合でも、ギブス・サンプリングとのサンプリングも含めた反復回数の違いは
`1024 * 4096 : 32 * 65536 = 2 : 1`と半分で、
しかも活性化関数の呼び出しが少ないために各反復での計算量も少なくなっている。

